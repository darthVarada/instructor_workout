import os
from datetime import datetime
import pandas as pd

from pathlib import Path
from instructor_workout.etl.utils.aws_client import get_s3

BUCKET = "instructor-workout-datas"

# Caminho ABSOLUTO dentro do seu projeto local
# (pois o container monta ../src e tamb√©m monta a raiz do projeto)
LOCAL_CSV_PATH = (
    "/opt/airflow/../data/silver/users_form_log_birthdate.csv"
)

def ingest_users_form():

    print("\n=== üì• Ingest√£o do Users Form ‚Üí S3 Bronze ===\n")
    print(f"üìå Lendo arquivo local: {LOCAL_CSV_PATH}")

    if not os.path.exists(LOCAL_CSV_PATH):
        raise FileNotFoundError(
            f"‚ùå Arquivo n√£o encontrado: {LOCAL_CSV_PATH}. "
            "Verifique se est√° montado corretamente no Docker."
        )

    df = pd.read_csv(LOCAL_CSV_PATH)

    # Nome √∫nico p/ evitar sobrescrita
    today = datetime.today().strftime("%Y%m%d")
    parquet_filename = f"users_form_{today}.parquet"
    tmp_parquet = f"/tmp/{parquet_filename}"

    print("‚û°Ô∏è Convertendo CSV ‚Üí Parquet...")
    df.to_parquet(tmp_parquet, index=False)

    # Prefixo bronze/raw
    s3_key = f"bronze/raw/users_form_log_birthdate/{parquet_filename}"

    print(f"‚¨ÜÔ∏è Upload para s3://{BUCKET}/{s3_key}")
    s3 = get_s3()

    try:
        s3.upload_file(tmp_parquet, BUCKET, s3_key)
        print("‚úîÔ∏è Upload conclu√≠do com sucesso!")
    except Exception as e:
        print(f"‚ùå Erro no upload para o S3: {e}")
        raise

    print("\n=== ‚úî Finalizado: Users Form ‚Üí Bronze ===\n")


if __name__ == "__main__":
    ingest_users_form()
